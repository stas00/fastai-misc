{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pynvml\n",
    "pynvml = pynvml\n",
    "pynvml.nvmlInit()\n",
    "nvml_preload = 0\n",
    "nvml_prev = 0\n",
    "pytorch_prev = 0\n",
    "def nvml_used():\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(torch.cuda.current_device())\n",
    "    info   = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    return b2mb(info.used)\n",
    "def b2mb(x): return int(x/2**20)\n",
    "def consume_gpu_ram(n): return torch.ones((n, n)).cuda()\n",
    "def consume_gpu_ram_64mb():  return consume_gpu_ram(2**12)\n",
    "def consume_gpu_ram_256mb(): return consume_gpu_ram(2**13)\n",
    "def mem(): \n",
    "    global nvml_preload, nvml_prev, pytorch_preload, pytorch_prev\n",
    "    nvml_this = nvml_used()\n",
    "    nvml_delta_cached = nvml_this - nvml_preload\n",
    "    nvml_delta_used = nvml_this - nvml_prev\n",
    "    nvml_prev = nvml_this\n",
    "    \n",
    "    pytorch_this = torch.cuda.memory_allocated()\n",
    "    pytorch_delta_used = pytorch_this - pytorch_prev\n",
    "    pytorch_prev = pytorch_this\n",
    "    \n",
    "    print(f\"   nvml used: {nvml_delta_used:4d}, allocated: {nvml_delta_cached:4d}\")\n",
    "    print(f\"pytorch used: {b2mb(pytorch_delta_used):4d}, allocated: {b2mb(torch.cuda.memory_cached()):4d}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preloading:\n",
      "   nvml used: 4779, allocated: 4779\n",
      "pytorch used:    0, allocated:    0\n",
      "\n",
      "   nvml used:  495, allocated: 5274\n",
      "pytorch used:    0, allocated:    1\n",
      "\n",
      "\n",
      "running:\n",
      "   nvml used:   64, allocated: 5338\n",
      "pytorch used:   64, allocated:   65\n",
      "\n",
      "   nvml used:  256, allocated: 5594\n",
      "pytorch used:  256, allocated:  321\n",
      "\n",
      "   nvml used:    0, allocated: 5594\n",
      "pytorch used: -256, allocated:  321\n",
      "\n",
      "   nvml used:    0, allocated: 5594\n",
      "pytorch used:   64, allocated:  321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"preloading:\")\n",
    "mem()\n",
    "_ = torch.ones((1, 1)).cuda()\n",
    "mem()\n",
    "preload = nvml_used()\n",
    "pytorch_preload = torch.cuda.memory_allocated()\n",
    "\n",
    "print(\"\\nrunning:\")\n",
    "x1 = consume_gpu_ram_64mb()\n",
    "mem()\n",
    "x2 = consume_gpu_ram_256mb()\n",
    "mem()\n",
    "del x2\n",
    "mem()\n",
    "x3 = consume_gpu_ram_64mb()\n",
    "mem()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
